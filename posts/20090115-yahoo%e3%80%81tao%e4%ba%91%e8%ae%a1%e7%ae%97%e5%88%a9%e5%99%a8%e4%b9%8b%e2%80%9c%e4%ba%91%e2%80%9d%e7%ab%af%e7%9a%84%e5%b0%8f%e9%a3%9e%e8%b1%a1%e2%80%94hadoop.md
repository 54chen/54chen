title: yahoo、taobao云计算利器之“云”端的小飞象—Hadoop
link: http://www.54chen.com/_linux_/yahoo%e3%80%81tao%e4%ba%91%e8%ae%a1%e7%ae%97%e5%88%a9%e5%99%a8%e4%b9%8b%e2%80%9c%e4%ba%91%e2%80%9d%e7%ab%af%e7%9a%84%e5%b0%8f%e9%a3%9e%e8%b1%a1%e2%80%94hadoop.html
author: cc0cc
description: 
post_id: 399
created: 2009/01/15 10:40:11
created_gmt: 2009/01/15 02:40:11
comment_status: open
post_name: yahoo%e3%80%81tao%e4%ba%91%e8%ae%a1%e7%ae%97%e5%88%a9%e5%99%a8%e4%b9%8b%e2%80%9c%e4%ba%91%e2%80%9d%e7%ab%af%e7%9a%84%e5%b0%8f%e9%a3%9e%e8%b1%a1%e2%80%94hadoop
status: publish
post_type: post

# yahoo、taobao云计算利器之“云”端的小飞象—Hadoop

**“云”端的小飞象****—Hadoop**

孙 牧

### Hadoop简史

在搜索技术界，也许有人不熟悉Doug Cutting，但很少有人不知道Lucene这个著名的全文检索引擎。事实上，Lucene应该是Doug Cutting的成名作，它被广泛地应用在各种规模的网站和系统中，甚至Eclipse中的搜索功能也是Lucene来实现的。

 

但Doug Cutting并没有满足Lucene取得的成绩。2002年，他发起了一个基于Lucene的开源项目Nutch，其目标是构建出一个包括网络蜘蛛、文件存储等模块的网页搜索系统。经过2年的努力，Nutch虽然可以用4台机器支持1亿网页的抓取和检索，但系统的扩展性开始遇到瓶颈。恰在此时，Google发表了GFS、MapReduce的论文，这两个创新性的思路点燃了Nutch 2名开发人员的斗志，他们又花了2年的业余时间实现了DFS（分布式文件系统）和MapReduce机制，这次改造使Nutch可以在20台机器上支持几亿的数据规模，其编程和运维的简易性也得到了大幅提升，但系统的吞吐能力与一个真正的网页搜索系统仍有不小的差距。

 

2006年，开源社区如火如荼，当美国雅虎在思索构建一个高度利用硬件资源、维护和开发都非常简易的软件架构时，Doug Cutting和他的Nutch进入了他们的视野。一方具有超强的技术前瞻性和实战经验，另一方能提供世界上数一数二的数据、硬件和人力资源，双方一拍即合，同年1月Doug Cutting正式加入雅虎，2月Hadoop从Nutch中分离出来，正式成为Apache组织中一个专注于DFS和MapReduce的开源项目。

 

2008年2月，又是两年，雅虎宣布搭建出一个世界上最大的基于Hadoop的生产集群系统—Yahoo! Search Webmap（简单地讲，就是雅虎网页搜索抓取的所有站点和网页及其关系的数据库），下面一组数据可以让我们对该系统的规模有个初步的认识：

Ø  页面之间的链接数超过1000亿；

Ø  Webmap输出的压缩数据超过300TB（Terabyte）；

Ø  有单一的MapReduce任务同时在1万多个CPU的核（core）上运行；

Ø  生产集群硬盘空间占用超过5PB（Petabyte）；

Ø  与原来没用Hadoop的方案相比节约了30%的时间。

 

这时候，可以说Doug Cutting想构建一个Web-scale级别系统的心愿也终于实现了！

 

### Hadoop的系统架构

简单地讲，Hadoop是一个可以更容易开发和并行处理大规模数据的分布式计算平台。它的主要特点是：**扩容能力（****Scalable****）**、**成本低（****Economical****）**、**高效率（****Efficient****）**、**可靠性（****Reliable****）**。另外，Hadoop是一款完全用Java开发的开源软件，因此它可以运行在多种操作系统和商用硬件上。

 

Hadoop主要由两部分构成：Hadoop分布式文件系统（HDFS）和MapReduce的实现。

HDFS和MapReduce的关系如下图所示：

![](/wp-content/uploads/2009/01/1.jpg)

MapReduce是依赖于HDFS实现的。通常MapReduce会将被计算的数据分为很多小块，HDFS会将每个块复制若干份以确保系统的可靠性，同时它按照一定的规则将数据块放置在集群中的不同机器上，以便MapReduce在数据宿主机器上进行最便捷的计算。

 

下面我们再深入一些看看HDFS和MapReduce的实现细节：

## Comments

**[cc0cc](#135 "2009-01-15 10:53:37"):** 再附一个 http://www.ibm.com/developerworks/cn/linux/l-hadoop/?ca=drs-tp4608 使用 Linux 和 Hadoop 进行分布式计算

**[性感的西瓜](#136 "2009-01-15 13:44:45"):** 好复杂。。。。。。。。

**[疏影](#137 "2009-01-15 13:46:25"):** 沙发没了，还有张板凳，快点

**[cc0cc](#138 "2009-01-15 16:54:02"):** 你两个占楼很积极，特此表扬，哈哈

**[小七](#139 "2009-01-16 12:21:03"):** 也夸我一个

**[cc0cc](#245 "2009-03-23 11:59:23"):** 小七也很积极 嘎嘎

